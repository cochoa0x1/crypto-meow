{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Kitten Cattributes\n",
    "\n",
    "### Slightly Evil\n",
    "\n",
    "Unfortunately the attributes such as 'dali' or 'otaku' are not listed anywhere in the blockchain. They are calculated from the cat's genes in a black box manner. I would like to decipher that black box but I need data first. So unfortunately I need to scrape the site. To lessen the burden on the the main site I will scrape two other sites that have already themselves scrapped the main site for these attributes. I won't parallelize it and just let it run as long as it takes, its a one time thing. I also just take a small sample, I don't need every cat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "from lxml import html\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "from subprocess import call\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 9999\n"
     ]
    }
   ],
   "source": [
    "#don't download any cats we currently have\n",
    "df = pd.read_csv('smaller_sample.csv')\n",
    "cat_db = df.set_index('id',drop=False).to_dict(orient='index')\n",
    "print(min(cat_db.keys()),max(cat_db.keys()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cat(cat_id):\n",
    "    r = requests.get('https://api.cryptokitties.co/kitties/%s'%cat_id)\n",
    "    r.raise_for_status()\n",
    "    raw_data = r.json()\n",
    "    \n",
    "    keys_i_care_about = ['id', 'name', 'image_url', 'color', 'bio', 'is_fancy','cattributes']\n",
    "\n",
    "    data ={}\n",
    "\n",
    "    for k in keys_i_care_about:\n",
    "        data[k] = raw_data[k]\n",
    "    \n",
    "    data['source'] = 'https://api.cryptokitties.co/kitties'\n",
    "    return data\n",
    "\n",
    "def get_cat2(cat_id):\n",
    "    r = requests.get('http://www.kittyexplorer.com/kitties/%s'%cat_id)\n",
    "    r.raise_for_status()\n",
    "    \n",
    "    tree = html.fromstring(r.content)\n",
    "    \n",
    "    data={}\n",
    "    data['id'] = cat_id\n",
    "    data['image_url']=tree.xpath('/html/body/div/div[1]/div[1]/a/img/@src')[0]\n",
    "    data['color']= tree.xpath('/html/body/div/div[1]/div[1]/a/img/@style')[0]\n",
    "    data['name'] = tree.xpath('/html/body/div/div[1]/div[2]/h3/text()')[0]\n",
    "    data['bio'] = tree.xpath('/html/body/div/div[1]/div[2]/p[2]/text()')[0]\n",
    "    data['cattributes']= tree.xpath('/html/body/div/div[1]/div[2]/a/button/text()')\n",
    "    data['source'] = 'http://www.kittyexplorer.com'\n",
    "    return data\n",
    "\n",
    "def get_cat3(cat_id):\n",
    "    r = requests.get('http://cryptokittydex.com/kitties/%s'%cat_id)\n",
    "    r.raise_for_status()\n",
    "    \n",
    "    tree = html.fromstring(r.content)\n",
    "    \n",
    "    data={}\n",
    "    data['name']=tree.xpath('/html/body/div[2]/div/div[2]/h3[1]/text()')[0]\n",
    "    \n",
    "    im_url, color = tree.xpath('/html/body/div[2]/div/div[1]/div/div/a/@style')[0].split(';')\n",
    "\n",
    "    data['image_url'] = im_url[im_url.find('(')+1:im_url.find(')')]\n",
    "    if data['image_url'][-3:] not in ['svg','png']:\n",
    "        data['image_url']= None\n",
    "        \n",
    "    data['color'] = color\n",
    "    \n",
    "    data['cattributes'] = tree.xpath('/html/body/div[2]/div/div[2]/ul[1]/li[8]/a/text()')\n",
    "    data['id'] = cat_id\n",
    "   \n",
    "    data['source'] = 'http://cryptokittydex.com'\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cat_db={} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_cats(cat_db, start_idx=1, end_idx=100, chill_time=1, max_retry=4):\n",
    "    \n",
    "    #lets not go in order\n",
    "    to_get = [i for i in range(start_idx,end_idx) if i not in cat_db]\n",
    "    print('downloading %d many new cats'%len(to_get))\n",
    "    for i in tqdm_notebook(np.random.permutation(to_get)):\n",
    "        if i in cat_db:\n",
    "            continue\n",
    "\n",
    "        #simple retry logic\n",
    "        try_count =0\n",
    "        failed=True\n",
    "        while try_count <= max_retry and failed==True:\n",
    "            try_count+=1\n",
    "            try:    \n",
    "                func = np.random.choice([get_cat,get_cat2,get_cat3])\n",
    "                data = func(i)\n",
    "                failed = False\n",
    "                cat_db[i] = data\n",
    "                #print('*',end='')\n",
    "            except Exception as e:\n",
    "                dt = chill_time*try_count**2\n",
    "                print('x',end='')\n",
    "                sleep(dt)\n",
    "\n",
    "        sleep(chill_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading 0 many new cats\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8320ae9c88c4318a01cbc326e760238"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scrape_cats(cat_db,start_idx=1,end_idx=2,chill_time=.5, max_retry=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([ cat_db[k] for k in cat_db ])\n",
    "#df.sample(n=10)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('small_sample_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_already_downloaded = [ int(f.split('.')[0]) for f in os.listdir('images') if f[-3:] in ['svg','png']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "images_to_download = list(df[df.id.apply(lambda x: x not in ids_already_downloaded)].sort_values('source').image_url.dropna().values)[:500]\n",
    "print(len(images_to_download))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "commands =['wget','-P','images']+images_to_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call(commands)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
